{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Deploy our ML Model\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you will do:\n",
    " - Run a Preprocessing Job using Amazon SageMaker Processing Job\n",
    " - Run a Tensorflow Training Job using Amazon SageMaker Training Job\n",
    " - Register a new version of the trained model in the Amazon SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1/4 - Setup\n",
    "Here we'll import some libraries and define some variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from sagemaker import get_execution_role\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "from sagemaker.model_monitor import DataCaptureConfig\n",
    "import sagemaker.session\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "s3_client = boto3.client(\"s3\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 2/4 - Model Package Definition\n",
    "During this steps, we are retrieving model informations from the Amazon SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###Â Get Approved Model Packages\n",
    "\n",
    "This method can be used for returning the last approved model from the specified model package group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_package_group = \"ml-end-to-end-group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the latest approved model package\n",
    "    response = sagemaker_client.list_model_packages(\n",
    "        ModelPackageGroupName=model_package_group,\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=1,\n",
    "    )\n",
    "    approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "    # Return error if no packages found\n",
    "    if len(approved_packages) == 0:\n",
    "        error_message = (\"No approved ModelPackage found for ModelPackageGroup: {}\".format(model_package_group))\n",
    "        LOGGER.error(\"{}\".format(error_message))\n",
    "\n",
    "        raise Exception(error_message)\n",
    "\n",
    "    model_package = approved_packages[0]\n",
    "    LOGGER.info(\"Identified the latest approved model package: {}\".format(model_package))\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    error_message = e.response[\"Error\"][\"Message\"]\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### List Model Packages\n",
    "\n",
    "This method can be used for listing all the registered models in a Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_package_arn = model_package[\"ModelPackageArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model_package = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=model_package_arn\n",
    "    )\n",
    "\n",
    "    LOGGER.info(\"{}\".format(model_package))\n",
    "\n",
    "    if len(model_package) == 0:\n",
    "        error_message = (\"No ModelPackage found for: {}\".format(model_package_arn))\n",
    "        LOGGER.error(\"{}\".format(error_message))\n",
    "\n",
    "        raise Exception(error_message)\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    error_message = e.response[\"Error\"][\"Message\"]\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3/4 - Deploy an Amazon SageMaker Endpoint\n",
    "Here we are deploying an Amazon SageMaker Endpoint by using the ML model taken from the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role_name = \"mlops-sagemaker-execution-role\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(boto3.client('sts').get_caller_identity().get('Account'), role_name)\n",
    "\n",
    "kms_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "kms_alias = \"ml-kms\"\n",
    "\n",
    "bucket_artifacts = \"\"\n",
    "bucket_inference = \"\"\n",
    "\n",
    "inference_artifact_path = \"artifact/inference\"\n",
    "inference_artifact_name = \"sourcedir.tar.gz\"\n",
    "inference_instance_count = 1\n",
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "model_package_group = \"ml-end-to-end-group\"\n",
    "\n",
    "\n",
    "monitoring_output_path = \"data/monitoring/captured\"\n",
    "\n",
    "training_framework_version = 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kms_key = \"arn:aws:kms:{}:{}:alias/{}\".format(region, kms_account_id, kms_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_runtime_client=runtime_client,\n",
    "    default_bucket=bucket_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Compress source code for installing additional python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! ./../algorithms/buildspec.sh inference $bucket_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inference_source_dir = \"s3://{}/{}/{}\".format(\n",
    "    bucket_inference,\n",
    "    inference_artifact_path,\n",
    "    inference_artifact_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create SageMaker model\n",
    "\n",
    "This method can be used for creating a SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model = TensorFlowModel(\n",
    "        entry_point=\"inference.py\",\n",
    "        framework_version=str(training_framework_version),\n",
    "        source_dir=inference_source_dir,\n",
    "        model_data=model_package[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"],\n",
    "        model_kms_key=kms_key,\n",
    "        role=role,\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "except Exception as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Deploy a SageMaker Endpoint\n",
    "\n",
    "Lets deploy the endpoint. If we want to update an existing endpoint, we have to create a new endpoint configuration defined in the method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def update_model(session, model_name, model_package_group_name, env, inference_instance_count, inference_instance_type):\n",
    "    try:\n",
    "        LOGGER.info(\"Updating endpoint configuration {}\".format(model_package_group_name + \"-\" + env))\n",
    "\n",
    "        endpoint_config_name = session.create_endpoint_config(\n",
    "            name=\"{}-{}-{}\".format(model_package_group_name, env, datetime.today().strftime('%Y-%m-%d-%H-%M-%S')),\n",
    "            model_name=model_name,\n",
    "            initial_instance_count=inference_instance_count,\n",
    "            instance_type=inference_instance_type\n",
    "        )\n",
    "\n",
    "        response = sagemaker_client.update_endpoint(\n",
    "            EndpointName=model_package_group_name + \"-\" + env,\n",
    "            EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "\n",
    "        LOGGER.info(\"Update endpoint {}-{}\".format(model_package_group_name, env))\n",
    "        LOGGER.info(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.info(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    model.deploy(\n",
    "        endpoint_name=model_package_group + \"-dev\",\n",
    "        initial_instance_count=inference_instance_count,\n",
    "        instance_type=inference_instance_type,\n",
    "        update_endpoint=True,\n",
    "        data_capture_config=DataCaptureConfig(\n",
    "                enable_capture=True,\n",
    "                sampling_percentage=100,\n",
    "                json_content_types=[\"application/jsonlines\"],\n",
    "                destination_s3_uri=\"s3://{}/{}\".format(bucket_inference, monitoring_output_path))\n",
    "    )\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    LOGGER.info(\"{}\".format(stacktrace))\n",
    "\n",
    "    model_name = get_deployed_model()\n",
    "\n",
    "    update_model(session, model_name, model_package_group_name, env, inference_instance_count, inference_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Test the SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "model_package_group = \"ml-end-to-end-group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "predictor = TensorFlowPredictor(\n",
    "    endpoint_name=model_package_group + \"-dev\",\n",
    "    model_name=\"saved_model\",\n",
    "    model_version=1,\n",
    "    content_type=\"application/jsonlines\",\n",
    "    accept_type=\"application/jsonlines\",\n",
    "    serializer=JSONLinesSerializer(),\n",
    "    deserializer=JSONLinesDeserializer()\n",
    "    \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "inputs = [{\"features\": [\"Sei disgustoso\"]}]\n",
    "\n",
    "result = predictor.predict(inputs)\n",
    "\n",
    "LOGGER.info(\"{}\".format(result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 3/4 - Monitoring\n",
    "Here we are creating monitoring jobs for extracting metrics from our SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "###Â Create a Baseline for the monitoring job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "From our training dataset, let's select the relevant attributes and generate a dataset for baselining. Then we use Amazon SageMaker Model Monitor to suggest a set of baseline constraints and descriptive statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sagemaker.model_monitor import CronExpressionGenerator, DefaultModelMonitor\n",
    "from sagemaker.model_monitor.dataset_format import DatasetFormat\n",
    "from time import gmtime, strftime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bucket_artifacts = \"\"\n",
    "bucket_inference = \"\"\n",
    "\n",
    "monitoring_input_files_path = \"data/monitoring/input\"\n",
    "processing_output_files_path = \"data/output\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "cleaned_data = \"s3://{}/{}/processed_data.csv\".format(bucket_artifacts, processing_output_files_path)\n",
    "\n",
    "monitoring_data = \"s3://{}/{}/monitoring_data.csv\".format(bucket_artifacts, monitoring_input_files_path)\n",
    "\n",
    "columns = [\"text\", \"Sentiment\"]\n",
    "\n",
    "df = pd.read_csv(cleaned_data, usecols=columns)\n",
    "df.to_csv(monitoring_data, index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "baseline_input_path = \"s3://{}/{}\".format(bucket_inference, monitoring_input_files_path)\n",
    "baseline_output_path = \"s3://{}/data/monitoring/output\".format(bucket_inference)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Please note that running the baselining job will require 8-10 minutes. In the meantime, you can take a look at the Deequ library, used to execute these analyses with the default Model Monitor container: https://github.com/awslabs/deequ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monitor = DefaultModelMonitor(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.c5.4xlarge\",\n",
    "    volume_size_in_gb=20,\n",
    "    max_runtime_in_seconds=3600,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monitor.suggest_baseline(\n",
    "    baseline_dataset=baseline_input_path,\n",
    "    dataset_format=DatasetFormat.csv(header=True),\n",
    "    output_s3_uri=baseline_output_path,\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Create Monitoring Scheduler\n",
    "\n",
    "Here we are creating our monitoring scheduler. It will execute monitoring jobs with hourly schedule execution. When we create the schedule, we can also specify two scripts that will preprocess the records before the analysis takes place and execute post-processing at the end. For this example, we are not going to use a record preprocessor, and we are just specifying a post-processor that outputs some text for demo purposes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pygmentize ./../algorithms/monitoring/src/preprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!pygmentize ./../algorithms/monitoring/src/postprocess.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monitoring_code_prefix = \"artifact/monitoring\"\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket_artifacts).Object(monitoring_code_prefix + \"/preprocess.py\").upload_file(\"./../algorithms/monitoring/src/preprocess.py\")\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket_artifacts).Object(monitoring_code_prefix + \"/postprocess.py\").upload_file(\"./../algorithms/monitoring/src/postprocess.py\")\n",
    "\n",
    "preprocessor_path = \"s3://{}/{}/preprocess.py\".format(bucket_artifacts, monitoring_code_prefix)\n",
    "postprocessor_path = \"s3://{}/{}/postprocess.py\".format(bucket_artifacts, monitoring_code_prefix)\n",
    "\n",
    "LOGGER.info(preprocessor_path)\n",
    "LOGGER.info(postprocessor_path)\n",
    "\n",
    "reports_path = \"s3://{}/data/monitoring/reports\".format(bucket_inference)\n",
    "\n",
    "LOGGER.info(reports_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "endpoint_name = predictor.endpoint_name\n",
    "\n",
    "mon_schedule_name = \"\" + strftime(\"%Y-%m-%d-%H-%M-%S\", gmtime())\n",
    "\n",
    "monitor.create_monitoring_schedule(\n",
    "    monitor_schedule_name=mon_schedule_name,\n",
    "    endpoint_input=endpoint_name,\n",
    "    record_preprocessor_script=preprocessor_path,\n",
    "    post_analytics_processor_script=postprocessor_path,\n",
    "    output_s3_uri=reports_path,\n",
    "    statistics=monitor.baseline_statistics(),\n",
    "    constraints=monitor.suggested_constraints(),\n",
    "    schedule_cron_expression=CronExpressionGenerator.hourly(),\n",
    "    enable_cloudwatch_metrics=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "desc_schedule_result = monitor.describe_schedule()\n",
    "desc_schedule_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Delete Scheduler\n",
    "\n",
    "Once the schedule is created, it will kick of jobs at specified intervals. Note that if you are kicking this off after creating the hourly schedule, you might find the executions empty. You might have to wait till you cross the hour boundary (in UTC) to see executions kick off. Since we don't want to wait for the hour in this example we can delete the schedule and use the code in next steps to simulate what will happen when a schedule is triggered, by running an Amazon SageMaker Processing Job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monitor.delete_monitoring_schedule()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Manual monitoring execution\n",
    "\n",
    "In oder to trigger the execution manually, we first get all paths to data capture, baseline statistics, baseline constraints, etc. Then, we use a utility fuction, defined in monitoringjob_utils.py, to run the processing job."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.insert(0, os.path.abspath('./../scripts'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from monitoringjob_utils import run_model_monitor_job_processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bucket_inference = \"\"\n",
    "\n",
    "endpoint_name = predictor.endpoint_name\n",
    "current_endpoint_capture_prefix = \"data/monitoring/captured/{}\".format(endpoint_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role_name = \"mlops-sagemaker-execution-role\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(boto3.client('sts').get_caller_identity().get('Account'), role_name)\n",
    "\n",
    "result = s3_client.list_objects(Bucket=bucket_inference, Prefix=current_endpoint_capture_prefix)\n",
    "capture_files = [\"s3://{0}/{1}\".format(bucket_inference, capture_file.get(\"Key\")) for capture_file in result.get(\"Contents\")]\n",
    "\n",
    "data_capture_path = capture_files[len(capture_files) - 1][: capture_files[len(capture_files) - 1].rfind('/')]\n",
    "\n",
    "baseline_output_path = \"s3://{}/data/monitoring/output\".format(bucket_artifacts)\n",
    "\n",
    "statistics_path = baseline_output_path + \"/statistics.json\"\n",
    "constraints_path = baseline_output_path + \"/constraints.json\"\n",
    "\n",
    "LOGGER.info(\"Capture Files: \")\n",
    "LOGGER.info(\"\\n \".join(capture_files))\n",
    "LOGGER.info(data_capture_path)\n",
    "LOGGER.info(statistics_path)\n",
    "LOGGER.info(constraints_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "run_model_monitor_job_processor(\n",
    "    region, \n",
    "    \"ml.m5.xlarge\", \n",
    "    role, \n",
    "    data_capture_path, \n",
    "    statistics_path, \n",
    "    constraints_path, \n",
    "    reports_path,\n",
    "    preprocessor_path=preprocessor_path,\n",
    "    postprocessor_path=postprocessor_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Analysis\n",
    "\n",
    "Here we are analyzing the report created by our Monitoring Job"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "bucket_inference = \"\"\n",
    "\n",
    "reports_path = \"data/monitoring/reports\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "monitoring_reports_prefix = \"{}/{}\".format(reports_path, predictor.endpoint_name)\n",
    "\n",
    "result = s3_client.list_objects(Bucket=bucket_inference, Prefix=monitoring_reports_prefix)\n",
    "\n",
    "try:\n",
    "    monitoring_reports = ['s3://{0}/{1}'.format(bucket_inference, capture_file.get(\"Key\")) for capture_file in result.get('Contents')]\n",
    "    print(\"Monitoring Reports Files: \")\n",
    "    print(\"\\n \".join(monitoring_reports))\n",
    "except:\n",
    "    print('No monitoring reports found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "!aws s3 cp {monitoring_reports[0]} ./../data/monitoring/\n",
    "!aws s3 cp {monitoring_reports[1]} ./../data/monitoring/\n",
    "!aws s3 cp {monitoring_reports[2]} ./../data/monitoring/\n",
    "!aws s3 cp {monitoring_reports[3]} ./../data/monitoring/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "file = open('./../data/monitoring/constraint_violations.json', 'r')\n",
    "data = file.read()\n",
    "\n",
    "violations_df = pd.json_normalize(json.loads(data)['violations'])\n",
    "violations_df"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}