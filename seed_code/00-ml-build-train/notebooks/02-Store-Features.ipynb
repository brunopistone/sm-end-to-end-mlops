{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Store features by using Amazon SageMaker Feature Store\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you will do:\n",
    " - Create a feature group for storing processed data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 1/2 - Setup\n",
    "Here we'll import some libraries and define some variables. You can also take a look on the scripts that were previously created for preparing the data and training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import csv\n",
    "import logging\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker.feature_store.feature_group import FeatureGroup\n",
    "from sagemaker.feature_store.feature_definition import FeatureDefinition, FeatureTypeEnum\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "featurestore_runtime_client = boto3.client(\"sagemaker-featurestore-runtime\")\n",
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Global configurations\n",
    "\n",
    "Configuration variables used for Processing, Training, and registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role_name = \"mlops-sagemaker-execution-role\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(boto3.client('sts').get_caller_identity().get('Account'), role_name)\n",
    "\n",
    "kms_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "kms_alias = \"ml-kms\"\n",
    "\n",
    "bucket_name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_runtime_client=runtime_client,\n",
    "    default_bucket=bucket_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "kms_key = \"arn:aws:kms:{}:{}:alias/{}\".format(region, kms_account_id, kms_alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "## Part 2/2: Store Features in Amazon SageMaker Feature Store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 1/4: Load datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_store_path = \"data/feature_store\"\n",
    "\n",
    "processing_output_files_path = \"data/output\"\n",
    "processed_train_data = \"train/train.csv\"\n",
    "processed_test_data = \"test/test.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data = pd.read_csv(\n",
    "                \"s3://{}/{}/{}\".format(bucket_name, processing_output_files_path, processed_train_data),\n",
    "                sep=',',\n",
    "                quotechar='\"',\n",
    "                quoting=csv.QUOTE_ALL,\n",
    "                escapechar='\\\\',\n",
    "                encoding='utf-8',\n",
    "                error_bad_lines=False\n",
    "            )\n",
    "\n",
    "test_data = pd.read_csv(\n",
    "                \"s3://{}/{}/{}\".format(bucket_name, processing_output_files_path, processed_test_data),\n",
    "                sep=',',\n",
    "                quotechar='\"',\n",
    "                quoting=csv.QUOTE_ALL,\n",
    "                escapechar='\\\\',\n",
    "                encoding='utf-8',\n",
    "                error_bad_lines=False\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.concat([train_data, test_data], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df = df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 2/4: Create Feature Groups\n",
    "\n",
    "Now let's create a feature group for the transaction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_feature_group_name = \"tweets-group-{}\".format(time.strftime('%m-%d-%H-%M', time.gmtime()))\n",
    "tweets_feature_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Define the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_feature_group = FeatureGroup(\n",
    "    name=tweets_feature_group_name, \n",
    "    sagemaker_session=sagemaker_session,\n",
    "    feature_definitions=[\n",
    "        FeatureDefinition(\n",
    "            feature_name=\"user_name\",\n",
    "            feature_type=FeatureTypeEnum.STRING\n",
    "        ),\n",
    "        FeatureDefinition(\n",
    "            feature_name=\"date\",\n",
    "            feature_type=FeatureTypeEnum.FRACTIONAL\n",
    "        ),\n",
    "        FeatureDefinition(\n",
    "            feature_name=\"text\",\n",
    "            feature_type=FeatureTypeEnum.STRING\n",
    "        ),\n",
    "        FeatureDefinition(\n",
    "            feature_name=\"Sentiment\",\n",
    "            feature_type=FeatureTypeEnum.FRACTIONAL\n",
    "        )\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Create the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "def wait_for_feature_group_creation_complete(feature_group):\n",
    "    status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    print(f'Initial status: {status}')\n",
    "    while status == 'Creating':\n",
    "        LOGGER.info(f'Waiting for feature group: {feature_group.name} to be created ...')\n",
    "        time.sleep(5)\n",
    "        status = feature_group.describe().get('FeatureGroupStatus')\n",
    "    if status != 'Created':\n",
    "        LOGGER.error(\"{}\".format(feature_group.describe().get(\"FailureReason\")))\n",
    "        raise SystemExit(f'Failed to create feature group {feature_group.name}: {status}')\n",
    "    LOGGER.info(f'FeatureGroup {feature_group.name} was successfully created.')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_feature_group.create(s3_uri=\"s3://{}/{}\".format(bucket_name, feature_store_path),\n",
    "                               record_identifier_name='user_name',\n",
    "                               event_time_feature_name='date',\n",
    "                               role_arn=role,\n",
    "                               enable_online_store=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "wait_for_feature_group_creation_complete(tweets_feature_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Ingest Data in the Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "tweets_feature_group.ingest(\n",
    "    data_frame=df, \n",
    "    max_processes=50, \n",
    "    wait=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 3/4 Get feature record from the Online feature store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "feature_record = featurestore_runtime_client.get_record(\n",
    "    FeatureGroupName=tweets_feature_group_name,\n",
    "    RecordIdentifierValueAsString=\"tiffany\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "LOGGER.info(feature_record)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "### Step 4/4 Explore Data from the Offline Feature Store\n",
    "\n",
    "Amazon SageMaker Feature Store creates an offline group by using Amazon S3. The data inside this bucket can be used for Training ML models or for performing batch inference by accessing data directly from the Amazon S3 bucket.\n",
    "\n",
    "Amazon SageMaker Feature Store for Offline groups is creating also a Catalog by using AWS Glue Data Catalog. You can retrieve data directly from the catalog by using [Amazon Athena](https://docs.aws.amazon.com/en_en/athena/latest/ug/what-is.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! aws s3 ls s3://$s3_bucket/$feature_store_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "#### Delete Feature Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "! aws sagemaker delete-feature-group --feature-group-name $tweets_feature_group_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "We have just seen how to prepare data using Amazon SageMaker Processing Job. In order to create a ML models please complete the following lab.\n",
    "\n",
    " > [Train-Build-Model](./03-Train-Build-Model.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "If we want to test the execution of a Custom Script container, we can execute the following lab.\n",
    " > [Train-Custom-Script-Container](./04-Train-Build-Model-Custom-Script-Container.ipynb)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}