{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training and Inference of our ML Model\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you will do:\n",
    " - Run a Preprocessing Job using Amazon SageMaker Processing Job\n",
    " - Run a Tensorflow Training Job using Amazon SageMaker Training Job\n",
    " - Register a new version of the trained model in the Amazon SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1/2 - Setup\n",
    "Here we'll import some libraries and define some variables. You can also take a look on the scripts that were previously created for preparing the data and training our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "import sagemaker\n",
    "from sagemaker import get_execution_role, image_uris\n",
    "from sagemaker.processing import Processor, ProcessingInput, ProcessingOutput\n",
    "from sagemaker.sklearn.processing import SKLearnProcessor\n",
    "from sagemaker.tensorflow import TensorFlow\n",
    "from sagemaker.model import Model\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "import time\n",
    "import traceback\n",
    "import yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")\n",
    "s3_client = boto3.client(\"s3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Global configurations\n",
    "\n",
    "Configuration variables used for Processing, Training, and registration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role_name = \"mlops-sagemaker-execution-role\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(boto3.client('sts').get_caller_identity().get('Account'), role_name)\n",
    "\n",
    "kms_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "kms_alias = \"ml-kms\"\n",
    "\n",
    "bucket_name = \"isengard-bpistone-ml-end-to-end-dev\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_runtime_client=runtime_client,\n",
    "    default_bucket=bucket_name\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_key = \"arn:aws:kms:{}:{}:alias/{}\".format(region, kms_account_id, kms_alias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2/2: Run the end to end ML workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1/3: Create the Processing Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processing_entrypoint = \"./../algorithms/processing/src/processing.py\"\n",
    "processing_framework_version = \"0.23-1\"\n",
    "processing_instance_count = 1\n",
    "processing_instance_type = \"ml.t3.large\"\n",
    "processing_input_files_path = \"data/input\"\n",
    "processing_output_files_path = \"data/output\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get the dataset and upload it to an S3 bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download the \n",
    "# clean the buckets first\n",
    "s3_client.delete_object(Bucket=bucket_name, Key=processing_input_files_path)\n",
    "\n",
    "input_data = sagemaker_session.upload_data('./../data/TheSocialDilemma.csv', key_prefix=processing_input_files_path )\n",
    "\n",
    "print(input_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Processor\n",
    "\n",
    "Lets create a SKLearn Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = SKLearnProcessor(\n",
    "    framework_version=processing_framework_version,\n",
    "    role=role,\n",
    "    instance_count=processing_instance_count,\n",
    "    instance_type=processing_instance_type,\n",
    "    output_kms_key=kms_key,\n",
    "    sagemaker_session=sagemaker_session\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "processor.run(\n",
    "    code=processing_entrypoint,\n",
    "    outputs=[\n",
    "        ProcessingOutput(\n",
    "            output_name=\"output\", \n",
    "            source=\"/opt/ml/processing/output\", \n",
    "            destination=\"s3://{}/{}\".format(bucket_name, processing_output_files_path))\n",
    "    ],\n",
    "    arguments = [\n",
    "        \"--input-data\",\n",
    "        \"s3://{}/{}\".format(bucket_name, processing_input_files_path)\n",
    "    ],\n",
    "    wait=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2/3: Create the Trining Job"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define input variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_artifact_path = \"artifact/training\"\n",
    "training_artifact_name = \"sourcedir.tar.gz\"\n",
    "training_output_files_path = \"models\"\n",
    "training_framework_version = \"2.4\"\n",
    "training_python_version = \"py37\"\n",
    "training_instance_count = 1\n",
    "training_instance_type = \"ml.p2.xlarge\"\n",
    "training_hyperparameters = {\n",
    "    \"epochs\": 5,\n",
    "    \"input_file\": \"processed_data.csv\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compress source code for installing additional python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./../algorithms/buildspec.sh training $bucket_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create Estimator\n",
    "\n",
    "Lets start a training job using a Tensorflow Estimator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator = TensorFlow(\n",
    "    entry_point=\"train.py\",\n",
    "    framework_version=training_framework_version,\n",
    "    py_version=training_python_version,\n",
    "    source_dir=\"s3://{}/{}/{}\".format(bucket_name,\n",
    "                                      training_artifact_path,\n",
    "                                      training_artifact_name\n",
    "                                      ),\n",
    "    output_path=\"s3://{}/{}\".format(bucket_name,\n",
    "                                    training_output_files_path),\n",
    "    hyperparameters=training_hyperparameters,\n",
    "    enable_sagemaker_metrics=True,\n",
    "    metric_definitions=[\n",
    "        {\n",
    "            'Name': 'Test accuracy',\n",
    "            'Regex': 'Test accuracy:.* ([0-9\\\\.]+)'\n",
    "        }\n",
    "    ],\n",
    "    role=role,\n",
    "    instance_count=training_instance_count,\n",
    "    instance_type=training_instance_type,\n",
    "    output_kms_key=kms_key,\n",
    "    disable_profiler=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit(\n",
    "    inputs={\n",
    "        \"train\": \"s3://{}/{}\".format(\n",
    "            bucket_name,\n",
    "            processing_output_files_path\n",
    "        ),\n",
    "    },\n",
    "    logs=\"Rules\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3/3: Register Model in the Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Input Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "\n",
    "model_package_group_name = \"ml-end-to-end-group\"\n",
    "model_approval_status = \"PendingManualApproval\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.register(\n",
    "    model_package_group_name=model_package_group_name,\n",
    "    approval_status=model_approval_status,\n",
    "    content_types=[\"application/json\"],\n",
    "    response_types=[\"application/json\"],\n",
    "    inference_instances=[inference_instance_type],\n",
    "    transform_instances=[inference_instance_type]\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
