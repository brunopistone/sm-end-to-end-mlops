{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deploy our ML Model\n",
    "\n",
    "**SageMaker Studio Kernel**: Data Science\n",
    "\n",
    "In this exercise you will do:\n",
    " - Run a Preprocessing Job using Amazon SageMaker Processing Job\n",
    " - Run a Tensorflow Training Job using Amazon SageMaker Training Job\n",
    " - Register a new version of the trained model in the Amazon SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1/3 - Setup\n",
    "Here we'll import some libraries and define some variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import required modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "from botocore.exceptions import ClientError\n",
    "from datetime import datetime\n",
    "import logging\n",
    "from sagemaker import get_execution_role\n",
    "import sagemaker.session\n",
    "from sagemaker.tensorflow import TensorFlowModel\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sagemaker_client = boto3.client(\"sagemaker\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(level=logging.INFO)\n",
    "LOGGER = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2/3 - Model Package Definition\n",
    "During this steps, we are retrieving model informations from the Amazon SageMaker Model Registry"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###Â Get Approved Model Packages\n",
    "\n",
    "This method can be used for returning the last approved model from the specified model package group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group = \"ml-end-to-end-group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    # Get the latest approved model package\n",
    "    response = sagemaker_client.list_model_packages(\n",
    "        ModelPackageGroupName=model_package_group,\n",
    "        ModelApprovalStatus=\"Approved\",\n",
    "        SortBy=\"CreationTime\",\n",
    "        SortOrder=\"Descending\",\n",
    "        MaxResults=1,\n",
    "    )\n",
    "    approved_packages = response[\"ModelPackageSummaryList\"]\n",
    "\n",
    "    # Return error if no packages found\n",
    "    if len(approved_packages) == 0:\n",
    "        error_message = (\"No approved ModelPackage found for ModelPackageGroup: {}\".format(model_package_group))\n",
    "        LOGGER.error(\"{}\".format(error_message))\n",
    "\n",
    "        raise Exception(error_message)\n",
    "\n",
    "    model_package = approved_packages[0]\n",
    "    LOGGER.info(\"Identified the latest approved model package: {}\".format(model_package))\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    error_message = e.response[\"Error\"][\"Message\"]\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### List Model Packages\n",
    "\n",
    "This method can be used for listing all the registered models in a Model Package Group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_arn = model_package[\"ModelPackageArn\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model_package = sagemaker_client.describe_model_package(\n",
    "        ModelPackageName=model_package_arn\n",
    "    )\n",
    "\n",
    "    LOGGER.info(\"{}\".format(model_package))\n",
    "\n",
    "    if len(model_package) == 0:\n",
    "        error_message = (\"No ModelPackage found for: {}\".format(model_package_arn))\n",
    "        LOGGER.error(\"{}\".format(error_message))\n",
    "\n",
    "        raise Exception(error_message)\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    error_message = e.response[\"Error\"][\"Message\"]\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise Exception(error_message)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3/3 - Deploy an Amazon SageMaker Endpoint\n",
    "Here we are deploying an Amazon SageMaker Endpoint by using the ML model taken from the Model Registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "region = boto3.session.Session().region_name\n",
    "role_name = \"mlops-sagemaker-execution-role\"\n",
    "role = \"arn:aws:iam::{}:role/{}\".format(boto3.client('sts').get_caller_identity().get('Account'), role_name)\n",
    "\n",
    "kms_account_id = boto3.client('sts').get_caller_identity().get('Account')\n",
    "\n",
    "kms_alias = \"ml-kms\"\n",
    "\n",
    "bucket_artifacts = \"isengard-bpistone-ml-end-to-end-dev\"\n",
    "bucket_inference = \"isengard-bpistone-ml-end-to-end-dev\"\n",
    "\n",
    "inference_artifact_path = \"artifact/inference\"\n",
    "inference_artifact_name = \"sourcedir.tar.gz\"\n",
    "inference_instance_count = 1\n",
    "inference_instance_type = \"ml.m5.xlarge\"\n",
    "model_package_group = \"ml-end-to-end-group\"\n",
    "training_framework_version = 2.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kms_key = \"arn:aws:kms:{}:{}:alias/{}\".format(region, kms_account_id, kms_alias)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "boto_session = boto3.Session(region_name=region)\n",
    "\n",
    "sagemaker_client = boto_session.client(\"sagemaker\")\n",
    "runtime_client = boto_session.client(\"sagemaker-runtime\")\n",
    "\n",
    "sagemaker_session = sagemaker.session.Session(\n",
    "    boto_session=boto_session,\n",
    "    sagemaker_client=sagemaker_client,\n",
    "    sagemaker_runtime_client=runtime_client,\n",
    "    default_bucket=bucket_inference\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compress source code for installing additional python modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ./../algorithms/buildspec.sh inference $bucket_artifacts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_source_dir = \"s3://{}/{}/{}\".format(\n",
    "    bucket_inference,\n",
    "    inference_artifact_path,\n",
    "    inference_artifact_name\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create SageMaker model\n",
    "\n",
    "This method can be used for creating a SageMaker model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model = TensorFlowModel(\n",
    "        entry_point=\"inference.py\",\n",
    "        framework_version=str(training_framework_version),\n",
    "        source_dir=inference_source_dir,\n",
    "        model_data=model_package[\"InferenceSpecification\"][\"Containers\"][0][\"ModelDataUrl\"],\n",
    "        model_kms_key=kms_key,\n",
    "        role=role,\n",
    "        sagemaker_session=sagemaker_session\n",
    "    )\n",
    "except Exception as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    LOGGER.error(\"{}\".format(stacktrace))\n",
    "\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Deploy a SageMaker Endpoint\n",
    "\n",
    "Lets deploy the endpoint. If we want to update an existing endpoint, we have to create a new endpoint configuration defined in the method below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_model(session, model_name, model_package_group_name, env, inference_instance_count, inference_instance_type):\n",
    "    try:\n",
    "        LOGGER.info(\"Updating endpoint configuration {}\".format(model_package_group_name + \"-\" + env))\n",
    "\n",
    "        endpoint_config_name = session.create_endpoint_config(\n",
    "            name=\"{}-{}-{}\".format(model_package_group_name, env, datetime.today().strftime('%Y-%m-%d-%H-%M-%S')),\n",
    "            model_name=model_name,\n",
    "            initial_instance_count=inference_instance_count,\n",
    "            instance_type=inference_instance_type\n",
    "        )\n",
    "\n",
    "        response = sagemaker_client.update_endpoint(\n",
    "            EndpointName=model_package_group_name + \"-\" + env,\n",
    "            EndpointConfigName=endpoint_config_name\n",
    "        )\n",
    "\n",
    "        LOGGER.info(\"Update endpoint {}-{}\".format(model_package_group_name, env))\n",
    "        LOGGER.info(response)\n",
    "\n",
    "    except Exception as e:\n",
    "        stacktrace = traceback.format_exc()\n",
    "        LOGGER.info(\"{}\".format(stacktrace))\n",
    "\n",
    "        raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    model.deploy(\n",
    "        endpoint_name=model_package_group + \"-dev\",\n",
    "        initial_instance_count=inference_instance_count,\n",
    "        instance_type=inference_instance_type,\n",
    "        update_endpoint=True\n",
    "    )\n",
    "except ClientError as e:\n",
    "    stacktrace = traceback.format_exc()\n",
    "    LOGGER.info(\"{}\".format(stacktrace))\n",
    "\n",
    "    model_name = get_deployed_model()\n",
    "\n",
    "    update_model(session, model_name, model_package_group_name, env, inference_instance_count, inference_instance_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the SageMaker Endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_package_group = \"ml-end-to-end-group\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker.tensorflow.model import TensorFlowPredictor\n",
    "from sagemaker.serializers import JSONLinesSerializer\n",
    "from sagemaker.deserializers import JSONLinesDeserializer\n",
    "\n",
    "predictor = TensorFlowPredictor(\n",
    "    endpoint_name=model_package_group + \"-dev\",\n",
    "    model_name=\"saved_model\",\n",
    "    model_version=1,\n",
    "    content_type=\"application/jsonlines\",\n",
    "    accept_type=\"application/jsonlines\",\n",
    "    serializer=JSONLinesSerializer(),\n",
    "    deserializer=JSONLinesDeserializer(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = [{\"features\": [\"Sei uno stupido\"]}]\n",
    "\n",
    "result = predictor.predict(inputs)\n",
    "\n",
    "LOGGER.info(\"{}\".format(result))"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "interpreter": {
   "hash": "7830b2e0dcc405ab83456d8c26dd7c2db32ddf1a7b2e64ef505b215ebac66515"
  },
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:eu-west-1:470317259841:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
